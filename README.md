
# Local LLM Web Crawler

## Overview

Local LLM Web Crawler is a tool designed to enhance the capabilities of large language models (LLMs) by enabling them to scroll through public web pages and answer questions based on their content. This project leverages advanced crawling techniques to gather relevant information from the web and integrate it seamlessly with LLMs.

## Features

- **Web Crawling:** Efficiently scrolls through public web pages to collect data.
- **Integration with LLMs:** Enhances the ability of LLMs to provide accurate answers based on real-time web content.
- **User-Friendly Interface:** Easy to set up and use for various applications.

## Tweet Mention

Check out what we're working on:

Check out this tweet by Me [Tweet](https://twitter.com/arpitwt/status/1789198928224616709)

## Installation

To get started with Local LLM Web Crawler, follow these steps:

1. **Clone the Repository**

```
git clone https://github.com/arpit-chokniwal/local-llm-web-croller.git
cd local-llm-web-croller
```

3. **Install Dependencies**

```
npm install package.json
```

4. **Run the Crawler**

```
npm start
```

## Usage

1. **Configure the Crawler**
   - Update the `Page url`.

2. **Start Crawling**
   - Run the crawler script to start gathering data.
   ```
   npm start
   ```
  
3. **Integrate with LLM**
   - Use the collected data to enhance the LLM's knowledge base.


## Contact

For any questions or suggestions, feel free to reach out:

- **Twitter:** [@arpitwt](https://twitter.com/arpitwt)
- **Email:** arpitchokniwal09@gmail.com

---

Thank you for checking out Local LLM Web Crawler! I hope you find it useful and look forward to your feedback and contributions.
